{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Application 02: Simulating Depth of Field using OpenCV and Gradio\n",
        "\n",
        "\n",
        "\n",
        "To simulate the focal properties of a real camera, we utilize a depth map. Depth of Field (DoF) creates sharp focus on the focal plane at a specific distance while keeping other areas blurred. It defines the range between the nearest and farthest objects that appear acceptably sharp in an image.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "j4Bp6xBr6Vo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title _\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "html_code = \"\"\"\n",
        "<style>\n",
        "  /* Hide the code cell itself in Colab */\n",
        "  div.cell.code_cell {\n",
        "      display: none;\n",
        "  }\n",
        "</style>\n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "  <figure style=\"display: inline-block;\">\n",
        "    <video id=\"autoplayVideo\" autoplay loop muted playsinline width=\"1080\">\n",
        "      <source src=\"https://learnopencv.com/wp-content/uploads/2025/01/Depth-of-filed-output-DepthPro-Output-Monocular-depth-applications.webm\" type=\"video/webm\">\n",
        "    </video>\n",
        "    <figcaption>Simulating Depth of Field Effect with OpenCV</figcaption>\n",
        "  </figure>\n",
        "</div>\n",
        "\n",
        "<script>\n",
        "  document.addEventListener(\"DOMContentLoaded\", function() {\n",
        "    var video = document.getElementById(\"autoplayVideo\");\n",
        "    video.play();\n",
        "  });\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(html_code))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "cellView": "form",
        "id": "RotxYzlXLzjF",
        "outputId": "52562101-f388-491c-ed9b-88dd3cb3983c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "  /* Hide the code cell itself in Colab */\n",
              "  div.cell.code_cell {\n",
              "      display: none;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "<div style=\"text-align: center;\">\n",
              "  <figure style=\"display: inline-block;\">\n",
              "    <video id=\"autoplayVideo\" autoplay loop muted playsinline width=\"1080\">\n",
              "      <source src=\"https://learnopencv.com/wp-content/uploads/2025/01/Depth-of-filed-output-DepthPro-Output-Monocular-depth-applications.webm\" type=\"video/webm\">\n",
              "    </video>\n",
              "    <figcaption>Simulating Depth of Field Effect with OpenCV</figcaption>\n",
              "  </figure>\n",
              "</div>\n",
              "\n",
              "<script>\n",
              "  document.addEventListener(\"DOMContentLoaded\", function() {\n",
              "    var video = document.getElementById(\"autoplayVideo\");\n",
              "    video.play();\n",
              "  });\n",
              "</script>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Introduction\n",
        "\n",
        "Depth of Field (DoF) is a fundamental concept in photography and cinematography that determines which parts of an image appear sharp and which parts are blurred. In professional cameras, several key factors control DoF, such as the lens aperture, focal length, sensor size, and perhaps most importantly, the **distance between your subject and the camera**.\n",
        "\n",
        "  \n",
        "\n",
        "Youâ€™ve probably noticed that portrait shots often showcase a beautifully blurred background where only a small portion of the image is in focusâ€”this is achieved using a shallow depth of field. Conversely, landscape shots typically feature everything sharply focused, a deep DoF keeps everything in focus thanks to a deep depth of field.\n",
        "\n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "    <img src=\"https://learnopencv.com/wp-content/uploads/2025/04/depth-of-field-and-focusing-distance.jpg\"\n",
        "         alt=\"Depth of Field and Focusing Distance\">\n",
        "    <p style=\"font-size: 14px; color: gray;\">Source: <a href=\"https://capturetheatlas.com/depth-of-field-photography/\" target=\"_blank\">capturetheatlas.com</a></p>\n",
        "</div>\n",
        "\n",
        "\n",
        "**Factors Affecting DoF**\n",
        "\n",
        "- **Aperture**: A wider aperture (lower f-stop) results in a shallower DoF, while a narrower aperture (higher f-stop) increases DoF.  \n",
        "\n",
        "- **Subject to Camera Distance**: A wider aperture (low f-stop number) gives you a shallow DoF with creamy background blur, perfect for portraits. A narrow aperture (higher f-stop number) keeps everything sharp, ideal for landscapes.\n",
        "  \n",
        "- **Lens Focal Length**: Longer lenses (telephoto) deliver a shallower DoF, making backgrounds more pleasantly blurred, whereas shorter lenses (wide-angle) keep a broader area in focus.\n",
        "\n",
        "- **Sensor Size**: Cameras with larger sensors naturally create shallower depth-of-field effects compared to smaller sensors like those found in smartphones.  \n",
        "\n",
        "\n",
        "### Simulating Depth of Field Using Image Processing  \n",
        "\n",
        "In this notebook of Depth Module, we aim to **simulate the effect of subject-to-camera distance** using computational techniques. Instead of relying on physical optics, we will generate a **depth-aware blur effect** using the following steps:  \n",
        "\n",
        "1. **Depth Estimation**: As usual we will first obtain a depth map from a single image using a monocular depth estimation model like DepthPro. This depth map serves as a proxy for the subject-to-camera distance.  \n",
        "\n",
        "2. **Depth-Based Blurring**: Using the depth map, we will apply a variable Gaussian blur, selectively defocusing parts of the image to mimic how real-world depth of field behaves. Objects further from your chosen focal point will softly blur, highlighting the intended subject.  \n",
        "\n",
        "While this method wonâ€™t perfectly replicate real-world optics, it allows us to create a convincing DoF effect using only computational techniques. This approach is widely used in computational photography and artificial bokeh effects in smartphone cameras.  \n",
        "\n",
        "If you're someone who already loves photography and understands manual camera settings, youâ€™ll absolutely love this process! **It's much like finely adjusting the focus ring on your DSLR lens to get that perfect shot frozen in time, with subjects in sharp focus.** ðŸ“¸  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "To know the nitty gritty details of Depth of Field in Professional Photography, check out this excellent [guide](https://photographylife.com/what-is-depth-of-field).\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Jcx5DkXLT0eS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Depth Prediction - Depth Pro Setup"
      ],
      "metadata": {
        "id": "zRony7pB21M4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!git clone https://github.com/apple/ml-depth-pro.git\n",
        "%cd ml-depth-pro\n",
        "!pip install -e ."
      ],
      "metadata": {
        "id": "FfRgqf0e-N4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the model checkpoint from huggingface\n",
        "%%capture\n",
        "!pip install huggingface-hub\n",
        "!pip install gradio\n",
        "!huggingface-cli download --local-dir checkpoints apple/DepthPro\n",
        "%cd .."
      ],
      "metadata": {
        "id": "S7m6PbWx-PBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To avoid depth pro import errors\n",
        "!pip install numpy==1.26.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5K7lMu__-QVa",
        "outputId": "c9882114-d908-4c62-d44f-9965a64d8c0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check numpy version - To work as expected it should be 1.26.4\n",
        "import numpy as np\n",
        "np.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dwB6EUYSLAMC",
        "outputId": "a5756eee-806a-47df-9523-b4aeafd92509"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ“Œ **Restart Session**"
      ],
      "metadata": {
        "id": "Lzc-YlNLKxuH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Import Dependencies"
      ],
      "metadata": {
        "id": "d3BMXU5N3FmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Tuple\n",
        "import time\n",
        "import torch\n",
        "\n",
        "# Add the src path for depth_pro\n",
        "sys.path.append('ml-depth-pro/src')\n",
        "!ln -s ml-depth-pro/checkpoints ./checkpoints # create a symbolic link to manage relative paths\n",
        "\n",
        "os.makedirs(\"input_images\",   exist_ok=True)\n",
        "os.makedirs(\"raw_depth_output\", exist_ok = True)\n",
        "os.makedirs(\"depth_blur_results\", exist_ok = True)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "acG8neDa-R8o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6f9323f-1280-4950-a73d-0fc912b8de7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ln: failed to create symbolic link './checkpoints/checkpoints': File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Depth Pro model"
      ],
      "metadata": {
        "id": "HPOVJaHC3KaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import depth_pro\n",
        "\n",
        "# Load model and preprocessing transform\n",
        "model, transform = depth_pro.create_model_and_transforms(precision=torch.half)\n",
        "model.to(\"cuda\").eval()\n",
        "print(\"Model Loaded Successfully...âœ…\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DWncHdV-WOH",
        "outputId": "b6abcc3d-f733-49ab-aac3-305688cc94cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Loaded Successfully...âœ…\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtain raw depth map and save the results"
      ],
      "metadata": {
        "id": "eCkoKCgB3Ovx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_depth(rgb_image: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    image = transform(rgb_image).to(\"cuda\")\n",
        "    prediction = model.infer(image)\n",
        "    depth = prediction[\"depth\"].detach().cpu().numpy().squeeze()\n",
        "    inverse_depth = 1 / depth\n",
        "\n",
        "    max_depth_vis = min(depth.max(), 1 / 0.1)\n",
        "    min_depth_vis = max(depth.min(), 1 / 250)\n",
        "\n",
        "    depth_clipped = np.clip(depth, min_depth_vis, max_depth_vis)\n",
        "\n",
        "    depth_normalized =(depth_clipped - min_depth_vis) / max_depth_vis\n",
        "\n",
        "    depth = (depth_normalized * 255)\n",
        "\n",
        "    grayscale_depth = depth.astype(np.uint8)\n",
        "\n",
        "    timestamp = int(time.time())\n",
        "    filename = f\"raw_depth_output/depth_map_{timestamp}.png\"\n",
        "    cv2.imwrite(filename, grayscale_depth)\n",
        "\n",
        "    return grayscale_depth"
      ],
      "metadata": {
        "id": "jkbzJZTTdl3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download images used in demo"
      ],
      "metadata": {
        "id": "nbh9gdcBwIzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://learnopencv.com/wp-content/uploads/2025/04/Leopard-Cub.jpeg -O leopard.jpeg\n",
        "!wget https://learnopencv.com/wp-content/uploads/2025/04/cave-scaled.jpg -O cave.jpg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_21G9sNNwNhe",
        "outputId": "285a76af-67f2-46e8-a910-c4922f6aca3f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-04 03:05:18--  https://learnopencv.com/wp-content/uploads/2025/04/Leopard-Cub.jpeg\n",
            "Resolving learnopencv.com (learnopencv.com)... 172.66.42.215, 172.66.41.41, 2606:4700:3108::ac42:2ad7, ...\n",
            "Connecting to learnopencv.com (learnopencv.com)|172.66.42.215|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 631634 (617K) [image/jpeg]\n",
            "Saving to: â€˜leopard.jpegâ€™\n",
            "\n",
            "leopard.jpeg        100%[===================>] 616.83K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-04-04 03:05:18 (19.5 MB/s) - â€˜leopard.jpegâ€™ saved [631634/631634]\n",
            "\n",
            "--2025-04-04 03:05:18--  https://learnopencv.com/wp-content/uploads/2025/04/cave-scaled.jpg\n",
            "Resolving learnopencv.com (learnopencv.com)... 172.66.42.215, 172.66.41.41, 2606:4700:3108::ac42:2ad7, ...\n",
            "Connecting to learnopencv.com (learnopencv.com)|172.66.42.215|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 678959 (663K) [image/jpeg]\n",
            "Saving to: â€˜cave.jpgâ€™\n",
            "\n",
            "cave.jpg            100%[===================>] 663.05K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-04-04 03:05:18 (20.3 MB/s) - â€˜cave.jpgâ€™ saved [678959/678959]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Depth of Field using Gradio\n",
        "\n",
        "\n",
        "Focal Plane (`focal_depth`): The imaginary plane where the image is perfectly in focus. Anything on this plane appears sharp, while objects in front or behind it become blurry.\n",
        "\n",
        "\n",
        "Focus Range  (`min_focal_range`): The distance between the nearest and farthest objects that appear acceptably sharp in an image. It varies based on aperture, focal length, and subject distance.\n",
        "\n",
        "---\n",
        "\n",
        "The `apply_dof` function simulates a Depth of Field (DoF) effect by selectively blurring parts of an image based on a depth map. This mimics the way real cameras focus on a subject while blurring the background or foreground.\n",
        "\n",
        "Let's understand step by step:\n",
        "\n",
        "Uses a Gaussian function to compute how much each pixel should remain sharp.\n",
        "1. Compute Sharpness Weights\n",
        "```python\n",
        "min_focal_range = 0.1  # Adjust as needed\n",
        "sharpness_weights = np.exp(-((depth_map_normalized - focal_depth) ** 2) / (2 * min_focal_range ** 2))\n",
        "```\n",
        "\n",
        "  - Uses a Gaussian function to compute how much each pixel should remain sharp.\n",
        "  - Pixels closer to focal_depth remain sharp, while others blur gradually.\n",
        "  - `min_focal_range` controls the focus transitionâ€”lower values create a sharper transition.\n",
        "\n",
        "2. Apply Gaussian Blur\n",
        "```python\n",
        "blurred_image = cv2.GaussianBlur(rgb_image, ksize = (51, 51), 0)\n",
        "```\n",
        "   -  Blurs the entire image using a Gaussian filter with a kernel size of (51, 51).\n",
        "\n",
        "  - Acts as the out-of-focus version of the image.\n",
        "\n",
        "3. Blend Sharp and Blurred Images\n",
        "```python\n",
        "sharpness_weights_3d = np.expand_dims(sharpness_weights, axis=2)\n",
        "dof_image = sharpness_weights_3d * rgb_image + (1 - sharpness_weights_3d) * blurred_image\n",
        "```\n",
        "  -  Expands sharpness_weights to match the image dimensions (H Ã— W Ã— 3).\n",
        "\n",
        "  - Blends the sharp and blurred images based on the weight mask.\n",
        "\n",
        "4. Final Depth of Field Output\n",
        "```python\n",
        "dof_image = np.clip(dof_image, 0, 255).astype(np.uint8)\n",
        "return dof_image\n",
        "```\n",
        "  - Ensures all pixel values are within the valid range `[0,255]`.\n",
        "\n",
        "  - Converts the image to uint8 format for proper display.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GEn3ZXjjOA9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stored_rgb, stored_depth = None, None # global var\n",
        "\n",
        "def apply_dof(rgb_image, focal_depth, raw_depth):\n",
        "\n",
        "    # Converts the depth map to a [0,1] range for consistency.\n",
        "    depth_map_normalized = cv2.normalize(src = raw_depth.astype(np.float32), dst = None, alpha = 0, beta = 1, norm_type = cv2.NORM_MINMAX)\n",
        "\n",
        "    min_focal_range = 0.10  # Adjust the focus range (region that will remain sharp) accordingly\n",
        "\n",
        "    sharpness_weights = np.exp(-((depth_map_normalized - focal_depth) **2) / (2 * min_focal_range ** 2))\n",
        "    sharpness_weights = sharpness_weights.astype(np.float32)\n",
        "\n",
        "    blurred_image = cv2.GaussianBlur(src = rgb_image, ksize = (51, 51), sigmaX = 0)\n",
        "\n",
        "    sharpness_weights_3d = np.expand_dims(sharpness_weights, axis = 2)\n",
        "\n",
        "    dof_image = sharpness_weights_3d * rgb_image + (1 - sharpness_weights_3d) * blurred_image\n",
        "\n",
        "    dof_image = np.clip(dof_image, 0, 255).astype(np.uint8)\n",
        "\n",
        "    return dof_image"
      ],
      "metadata": {
        "id": "U4qskDVOeu55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following ultiltiy `process_image` processes an input image, computes its depth map, and applies a Depth of Field (DoF) effect dynamically."
      ],
      "metadata": {
        "id": "lk1UehUozJ-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_image(rgb_image):\n",
        "    global stored_rgb, stored_depth\n",
        "    stored_rgb = rgb_image\n",
        "    stored_depth = predict_depth(rgb_image)\n",
        "    return stored_depth\n",
        "\n",
        "# depth of field\n",
        "def update_dof(focal_depth):\n",
        "    return apply_dof(stored_rgb, focal_depth, stored_depth)"
      ],
      "metadata": {
        "id": "imnK_lDogqAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally putting this all together into an interactive Gradio UI.\n",
        "\n",
        "The UI consists of **two tabs**:  \n",
        "\n",
        "1. **Predict Depth**  \n",
        "   - Upload an RGB image.  \n",
        "   - Predict and display the raw depth map.  \n",
        "\n",
        "2. **Depth of Field Effect**  \n",
        "   - Visualize the DoF effect.  \n",
        "   - Adjust the **focal depth** using a slider.  \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Once the code runs, a **public URL** will be generated.  \n",
        "Click on it to open the interface in a **new tab** and start playing with the DoF effect interactively!  \n",
        "\n",
        "\n",
        "> **Disclaimer:**  \n",
        "We have demonstrated an example using a **leopard image** and a scenic view, which correctly showcases the Depth of Field effect. However, **results may vary** for different images, as depth estimation accuracy depends on the scene complexity, lighting, and object structures.  \n",
        "\n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "  <figure style=\"display: inline-block;\">\n",
        "    <video\n",
        "       controls\n",
        "       src=\"https://learnopencv.com/wp-content/uploads/2025/04/c0_simulating_depth_effect.webm\"\n",
        "       width=\"1080\">\n",
        "    </video>\n",
        "    <figcaption>Gradio UI Demo</figcaption>\n",
        "  </figure>\n",
        "</div>\n",
        "\n"
      ],
      "metadata": {
        "id": "dnZ_QP3B2TIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "initial_focal_value = 0 # slider default value at start\n",
        "\n",
        "with gr.Blocks() as gui:\n",
        "    with gr.Tab(\"Predict Depth\"):\n",
        "        with gr.Row():\n",
        "            image_input = gr.Image(type=\"numpy\", label=\"Upload RGB Image\")\n",
        "            depth_output = gr.Image(type=\"numpy\", label=\"Predicted Raw Depth Map\")\n",
        "        process_button = gr.Button(\"Predict Depth\")\n",
        "        process_button.click(fn=process_image, inputs=image_input, outputs=depth_output)\n",
        "\n",
        "    with gr.Tab(\"Depth of Field Effect\"):\n",
        "        with gr.Row():\n",
        "            dof_output = gr.Image(type=\"numpy\", label=\"Depth of Field Effect\", width = 1920, height = 1080)\n",
        "        with gr.Row():\n",
        "            focal_slider = gr.Slider(0, 1, step = 0.01, value=initial_focal_value, label=\"Focal Depth Value\")\n",
        "            focal_slider.change(fn=update_dof, inputs=focal_slider, outputs=dof_output)\n",
        "\n",
        "gui.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "WS0LbrZoxift",
        "outputId": "2857a858-d037-4723-9525-08f1a40b586f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://c2b94416ae2191a4fa.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c2b94416ae2191a4fa.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7862 <> https://c2b94416ae2191a4fa.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Run locally using OpenCV trackbar window\n",
        "\n",
        "As we know, GUI-specific utilities do not work in the Colab environment. But if you want to truly feel the magic of this effect in real-time, try running it locally using an OpenCV trackbar!\n",
        "\n",
        "For this, you will need the depth map output of the input image, which is saved under `./raw_depth_output`.\n",
        "\n",
        "The real excitement kicks in when you slide the OpenCV trackbarâ€”youâ€™ll instantly see the depth effect shift smoothly with every tiny adjustment. Unlike Gradio, which introduces a slight transition delay, OpenCV renders changes instantaneouslyâ€”letting you truly appreciate the subtle in-focus to out-of-focus transitions.\n",
        "\n",
        "Just like in the leopard video shown at the start of the notebook, youâ€™ll notice how the blur dynamically adjusts, pulling your focus from the foreground to the background in a way that feels almost surreal.\n",
        "\n",
        "We highly recommend using the OpenCV version of this scriptâ€”just follow the instructions and enjoy the thrill of depth control at your fingertips."
      ],
      "metadata": {
        "id": "mo7-3NNG8W2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import cv2\n",
        "# import numpy as np\n",
        "\n",
        "\n",
        "# # Load RGB image and depth map\n",
        "# rgb_image = cv2.imread(\"Leopard-Cub.jpeg\")\n",
        "# depth_map = cv2.imread(\"raw_depth_output/depth_map_1743586939.png\", cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "\n",
        "# # Normalize depth map to range [0, 1]\n",
        "# depth_map_normalized = cv2.normalize(depth_map.astype(np.float32), None, 0, 1, cv2.NORM_MINMAX)\n",
        "\n",
        "# # Get screen size and resize image to fit\n",
        "# screen_width, screen_height = 1920, 1080  # Replace with your screen resolution if needed\n",
        "# scale = min(screen_width / rgb_image.shape[1], screen_height / rgb_image.shape[0])\n",
        "# new_width = int(rgb_image.shape[1] * scale)\n",
        "# new_height = int(rgb_image.shape[0] * scale)\n",
        "\n",
        "# rgb_image = cv2.resize(rgb_image, (new_width, new_height))\n",
        "# depth_map_normalized = cv2.resize(depth_map_normalized, (new_width, new_height))\n",
        "\n",
        "# # Function to apply depth of field effect\n",
        "# def apply_dof(focal_depth):\n",
        "#     focal_range = 0.1  # Range around focal depth to remain sharp\n",
        "\n",
        "#     # Create smooth focus weights\n",
        "#     sharpness_weights = np.exp(-((depth_map_normalized - focal_depth) ** 2) / (2 * focal_range ** 2))\n",
        "#     sharpness_weights = sharpness_weights.astype(np.float32)\n",
        "\n",
        "#     # Apply Gaussian blur to the background\n",
        "#     blurred_image = cv2.GaussianBlur(rgb_image, (51, 51), 0)\n",
        "\n",
        "#     # Blend the original image and blurred image using sharpness weights\n",
        "#     sharpness_weights_3d = np.expand_dims(sharpness_weights, axis=2)  # Add a channel for blending\n",
        "#     dof_image = sharpness_weights_3d * rgb_image + (1 - sharpness_weights_3d) * blurred_image\n",
        "#     dof_image = np.clip(dof_image, 0, 255).astype(np.uint8)\n",
        "\n",
        "#     return dof_image\n",
        "\n",
        "# # Callback function for the trackbar\n",
        "# def on_trackbar(val):\n",
        "#     # Convert slider value (0-100) to focal depth (0.0-1.0)\n",
        "#     focal_depth = val / 100.0\n",
        "#     dof_image = apply_dof(focal_depth)\n",
        "#     cv2.imshow(dof_image)\n",
        "\n",
        "# # Create a window and resize it to fit the screen\n",
        "# cv2.namedWindow(\"Depth of Field Effect\", cv2.WINDOW_NORMAL)\n",
        "# cv2.resizeWindow(\"Depth of Field Effect\", new_width, new_height)\n",
        "\n",
        "# # Create a trackbar (slider) at the top of the window\n",
        "# cv2.createTrackbar(\"Focal Plane\", \"Depth of Field Effect\", 50, 100, on_trackbar)  # Default at middle (50)\n",
        "\n",
        "# # Show initial DOF effect\n",
        "# initial_dof_image = apply_dof(0.5)  # Start with focal depth at 0.5\n",
        "# cv2.imshow(\"Depth of Field Effect\", initial_dof_image)\n",
        "\n",
        "# # Wait until user closes the window\n",
        "# cv2.waitKey(0)\n",
        "# cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "oMmaQSKp8aH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion  \n",
        "\n",
        "Interesting right! Run this application through your **wildest examples**, experiment with different images, and let us know if you were able to **improve the application** or came up with a **unique and interesting idea**â€”weâ€™d love to see what you create!  \n",
        "\n"
      ],
      "metadata": {
        "id": "koOfG971ef5g"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LLEQvP6BFYIM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}