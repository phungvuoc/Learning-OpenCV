{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:30px;\">Object Tracking Analysis</h1> \n",
    "\n",
    "In this notebook we will demonstrate how to execute multiple trackers and compare the results in a multi-view output video. This technique can be very valuable for assessing which tracking algorithm may be best suited for your particular application. \n",
    "\n",
    "<br>\n",
    "<center>\n",
    "<img src = \"https://opencv.org/wp-content/uploads/2021/09/c0-m16-02-Object-Tracker-Feature-Image.png\" alt=\"Object Tracker Feature Image\">\n",
    "</center>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    print(\"Downloading Code to Colab Environment\")\n",
    "    !wget https://www.dropbox.com/sh/uklrcxd2d4zfcp3/AAAQiMxAHkBlQUP-6wCzTa58a?dl=1 -O module-code.zip -q --show-progress\n",
    "    !unzip -qq module-code.zip\n",
    "    !pip install --upgrade opencv-contrib-python\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from moviepy.editor import VideoFileClip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.  Define Data Structures and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker_dict = dict(\n",
    "    BOOSTING   = cv2.legacy.TrackerBoosting_create(),\n",
    "    CSRT       = cv2.legacy.TrackerCSRT_create(),\n",
    "    KCF        = cv2.legacy.TrackerKCF_create(),\n",
    "    MEDIANFLOW = cv2.legacy.TrackerMedianFlow_create(),\n",
    "    MIL        = cv2.legacy.TrackerMIL_create(),\n",
    "    MOSSE      = cv2.legacy.TrackerMOSSE_create(),\n",
    "    TLD        = cv2.legacy.TrackerTLD_create(),\n",
    ")\n",
    "\n",
    "resolution_dict = {\n",
    "    '360p':(480,360),\n",
    "    '480p':(858,480),\n",
    "    '720p':(1280,720),\n",
    "    '1080p':(1920,1080)\n",
    "    }\n",
    "\n",
    "class VideoSpec:\n",
    "    # Constructor\n",
    "    def __init__(self,video_filename, resolution, bbox):\n",
    "        self.video_filename = video_filename\n",
    "        self.res = resolution\n",
    "        self.bbox = bbox\n",
    "\n",
    "def draw_bounding_box(frame, bbox, ok, color=(0, 255, 255), thickness=2):\n",
    "    if ok: \n",
    "        p1 = (int(bbox[0]), int(bbox[1]))\n",
    "        p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "        cv2.rectangle(frame, p1, p2, color, thickness)\n",
    "    else:\n",
    "        cv2.putText(frame, \"Tracking failure detected\", (10,80), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "\n",
    "\n",
    "def draw_banner_text(frame, text, banner_height_percent = 0.08, font_scale=1.5, font_thickness=2,\n",
    "                    text_alignment = \"center\",  text_color = (0,255,0)):\n",
    "    \n",
    "    # Draw a black filled banner across the top of the image frame.\n",
    "    # percent: banner height as a percentage of the frame height.\n",
    "    banner_height = int(banner_height_percent * frame.shape[0])\n",
    "    cv2.rectangle(frame, (0,0), (frame.shape[1],banner_height), (0,0,0), thickness=-1)\n",
    "    \n",
    "    # Draw text on banner\n",
    "    width = frame.shape[0]\n",
    "    alignment_dict = dict(left = width//4, center = width//2, right = width*3//4)\n",
    "    left_offset = alignment_dict[text_alignment]\n",
    "    location = (left_offset, banner_height - 10)\n",
    "    cv2.putText(frame, text, location, cv2.FONT_HERSHEY_PLAIN, font_scale, text_color, \n",
    "                font_thickness, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "def draw_text(frame, text, location=(20,20), font_scale=1, color=(50,170,50), font_thickness=2):\n",
    "    cv2.putText(frame, text, location, cv2.FONT_HERSHEY_SIMPLEX, font_scale, color,\n",
    "                font_thickness, cv2.LINE_AA)\n",
    "\n",
    "def get_trackers(tracker_names, tracker_dict):\n",
    "\n",
    "    tracker_objects = []\n",
    "    for tracker in tracker_names:\n",
    "        tracker_objects.append(tracker_dict[tracker])\n",
    "\n",
    "    return tracker_objects\n",
    "\n",
    "def initialize_trackers(tracker_objects, frame, bbox):\n",
    "\n",
    "    for tracker in tracker_objects:\n",
    "        tracker.init(frame, bbox)\n",
    "\n",
    "\n",
    "def get_tracker_results(tracker_objects, frame, tracker_names):\n",
    "\n",
    "    n = len(tracker_objects)\n",
    "    init_frames_list = [frame.copy() for i in range(n)]\n",
    "    final_frames_list = []\n",
    "\n",
    "    for i in range(n):\n",
    "        ok, result = update_tracker(tracker_objects[i], init_frames_list[i], tracker_names[i])\n",
    "        final_frames_list.append(result)\n",
    "\n",
    "    return final_frames_list\n",
    "\n",
    "\n",
    "def update_tracker(tracker, frame, tracker_type):\n",
    "    \n",
    "    timer = cv2.getTickCount()\n",
    "    \n",
    "    # Update tracker.\n",
    "    ok, bbox = tracker.update(frame)\n",
    "    \n",
    "    # Calculate Frames per second (FPS).\n",
    "    fps = cv2.getTickFrequency() / (cv2.getTickCount() - timer)\n",
    "    \n",
    "    # Draw bounding box.\n",
    "    draw_bounding_box(frame, bbox, ok)\n",
    "    \n",
    "    # Display tracker type on frame.\n",
    "    draw_banner_text(frame, tracker_type + ' Tracker' + ', FPS : ' + str(int(fps)))\n",
    "     \n",
    "    return ok, frame \n",
    "\n",
    "\n",
    "def get_output_video_dims(tracker_names, resolution_specs):\n",
    "    \n",
    "    width, height = resolution_specs\n",
    "    n = len(tracker_names)\n",
    "    if n == 1: \n",
    "        return width, height\n",
    "    if n == 2: \n",
    "        return width*2, height\n",
    "    if n == 4: \n",
    "        return width*2, height*2\n",
    "    if n == 6: \n",
    "        return width*3, height*2\n",
    "    if n == 8:\n",
    "        return width*4, height*2\n",
    "\n",
    "    \n",
    "def align_frames(frames_list):\n",
    "\n",
    "    n = len(frames_list)\n",
    "\n",
    "    if n == 1 :\n",
    "        return frames_list[0]\n",
    "\n",
    "    if n == 2: \n",
    "        return np.hstack([frames_list[0],frames_list[1]])\n",
    "    \n",
    "    if n == 4: \n",
    "        top = np.hstack([frames_list[0], frames_list[1]])\n",
    "        bottom = np.hstack([frames_list[2], frames_list[3]])\n",
    "        return np.vstack([top, bottom])\n",
    "\n",
    "    if n == 6: \n",
    "        top = np.hstack([frames_list[0], frames_list[1], frames_list[2]])\n",
    "        bottom = np.hstack([frames_list[3], frames_list[4], frames_list[5]])\n",
    "        return np.vstack([top, bottom])\n",
    "\n",
    "    if n == 8:  \n",
    "        top = np.hstack([frames_list[0], frames_list[1], frames_list[2], frames_list[3]])\n",
    "        bottom = np.hstack([frames_list[4], frames_list[5], frames_list[6], frames_list[7]])\n",
    "        return np.vstack([top, bottom])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define the Main Controller for Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tracker(tracker_names, video_spec, video_output_file_name):\n",
    "    \n",
    "    # Create the video capture object.\n",
    "    video_cap = cv2.VideoCapture(video_spec.video_filename)\n",
    "    \n",
    "    # Confirm video file can be opened.\n",
    "    if video_cap.isOpened():\n",
    "        width  = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps    = int(video_cap.get(cv2.CAP_PROP_FPS))\n",
    "    else: \n",
    "        print(\"Could not open video\")\n",
    "        sys.exit()\n",
    "        \n",
    "    # Set up video writer object for mp4.\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    fps_write = fps  # or other desired value\n",
    "    resolution_specs = resolution_dict.get(video_spec.res)\n",
    "    output_video_dim = get_output_video_dims(tracker_names, resolution_specs)\n",
    "    video_out = cv2.VideoWriter(video_output_file_name, fourcc, fps_write, output_video_dim)\n",
    "    \n",
    "    # Read the first frame.\n",
    "    ok, frame = video_cap.read()\n",
    "    if not ok:\n",
    "        print ('Cannot read video file')\n",
    "        sys.exit()\n",
    "\n",
    "    # Resize the image frame to the specified resolution.\n",
    "    frame = cv2.resize(frame, resolution_specs, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    # Get the list of tracker objects.\n",
    "    tracker_objects = get_trackers(tracker_names, tracker_dict)\n",
    "\n",
    "    # Initialize trackers.\n",
    "    initialize_trackers(tracker_objects, frame, video_spec.bbox)\n",
    "    \n",
    "    #-----------------------\n",
    "    # Process video frames.\n",
    "    #-----------------------\n",
    "    while True:\n",
    "\n",
    "        ok, frame = video_cap.read()\n",
    "        if not ok:\n",
    "            break      \n",
    "\n",
    "        # Resize the frame to the specified resolution.\n",
    "        frame = cv2.resize(frame, resolution_specs, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "        # Retrieve the results for each tracker.\n",
    "        frames_list = get_tracker_results(tracker_objects, frame, tracker_names)\n",
    "\n",
    "        # Compose the final results in a multi-view layout.\n",
    "        result = align_frames(frames_list)\n",
    "\n",
    "        video_out.write(result)    \n",
    "\n",
    "    video_cap.release()\n",
    "    video_out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Input Specification and Execution\n",
    "\n",
    "The following table summarizes the input specifications for the `race_car.mp4` test video clip. The initial bounding box is specified depending on the video resolution desired. Executing at full 1080p will likely cause significant latency in the video playback. It is therefore recommended that a lower resolution be specified when experimenting with several trackers (e.g., 480p). This can be helpful when making a rough assessment of the pros and cons of each tracker. However, be aware that the resolution will also potentially affect the actual tracking results, so the final testing you perform should be at a resolution that you expect for your particular application.\n",
    "\n",
    "`#------------------------------------------------------------------`<br>\n",
    "`# video_obj = VideoSpec(input_video, '360p',   (205, 170, 110, 60))    `<br>\n",
    "`# video_obj = VideoSpec(input_video, '480p',   (370, 225, 180, 80))    `<br>\n",
    "`# video_obj = VideoSpec(input_video, '720p',   (550, 340, 230, 115)    `<br>\n",
    "`# video_obj = VideoSpec(input_video, '1080p', (820, 510, 420, 180))`<br>\n",
    "`#------------------------------------------------------------------`<br>\n",
    "\n",
    "**Note**: The code cell below should only be executed once. If you want to execute it multiple times, you should re-run the previous code cells in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_video = './race_car.mp4'\n",
    "\n",
    "video_output_prefix = 'test_1x2'\n",
    "video_output_file_name = 'tracking_analysis_output_videos/' + video_output_prefix + '.mp4'\n",
    "\n",
    "# Define a list of trackers.\n",
    "trackers = ['BOOSTING', 'CSRT']\n",
    "\n",
    "# Create a video specification object.\n",
    "video_obj = VideoSpec(input_video, '480p',  (370, 225, 180, 80))\n",
    "\n",
    "# Execute trackers.\n",
    "run_tracker(trackers, video_obj, video_output_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:rgb(50,120,229)\">Display the tracking results: 1x2</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = VideoFileClip('tracking_analysis_output_videos/test_1x2.mp4')\n",
    "clip.ipython_display(width=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:rgb(50,120,229)\">Display the tracking results: 2x2</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = VideoFileClip('tracking_analysis_output_videos/test_2x2.mp4')\n",
    "clip.ipython_display(width=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:rgb(50,120,229)\">Display the tracking results: 2x3</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clip = VideoFileClip('tracking_analysis_output_videos/test_2x3.mp4')\n",
    "clip.ipython_display(width=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
