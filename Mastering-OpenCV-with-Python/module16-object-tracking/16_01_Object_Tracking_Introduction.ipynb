{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 style=\"font-size:30px;\">Introduction to Object Tracking</h1> \n",
    "\n",
    "Object tracking is an important and practical topic that has a very long history and has been applied to numerous fields. At a high level, tracking refers to estimating the state of an object (e.g., position and velocity) based on sensor measurements, and predicting its future location. For example, tracking the location of an aircraft based on radar measurements is a typical application of tracking. In the context of computer vision, tracking typically refers to processing video frames and predicting the location of an object (or multiple objects), in future video frames. \n",
    "\n",
    "In computer vision, this is accomplished using a motion model and an appearance model. The motion model will estimate the position and velocity of an object and use that information to predict the location of an object in future video frames and the appearance model encodes what the object looks like and then search the region around the predicted location from the motion model to then fine-tune the location of the object. So the motion model is an approximation to where the object might be located in a future video frame and the appearance model is used to fine-tune that estimate.\n",
    "\n",
    "\n",
    "OpenCV contains an API Tracker Class that includes several different tracker models which are all based on different algorithms. Depending on the application one model might be better suited than another. In this notebook, we will take a look as to how each of these models performs on a sample video of a race car."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <font style=\"color:rgb(50,120,229)\">Tracking Objective</font>\n",
    "\n",
    " Given the initial location of an object in a video stream, predict it's location in subsequent frames.\n",
    " \n",
    "<br>\n",
    "<center>\n",
    "<img src = \"https://opencv.org/wp-content/uploads/2021/09/c0-m16-01-Object-Tracker-Feature-Image.png\" alt=\"Object Tracker\">\n",
    "</center>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <font style=\"color:rgb(50,120,229)\">Tracking Models Available in the  OpenCV Tracker Class</font>\n",
    "\n",
    "1. BOOSTING\n",
    "2. CSRT\n",
    "3. KCF \n",
    "4. MEDIANFLOW\n",
    "5. MIL\n",
    "6. MOSSE\n",
    "7. TLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    print(\"Downloading Code to Colab Environment\")\n",
    "    !wget https://www.dropbox.com/sh/uklrcxd2d4zfcp3/AAAQiMxAHkBlQUP-6wCzTa58a?dl=1 -O module-code.zip -q --show-progress\n",
    "    !unzip -qq module-code.zip\n",
    "    !pip install --upgrade opencv-contrib-python\n",
    "else:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from moviepy.editor import VideoFileClip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preview Sample Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_video = './race_car.mp4'\n",
    "clip = VideoFileClip(input_video)\n",
    "clip.ipython_display(width=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define Annotation Convenience Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def drawBannerText(frame, text, banner_height_percent=0.08, font_scale=.8, text_color=(0, 255, 0), \n",
    "                   font_thickness=2):\n",
    "    # Draw a black filled banner across the top of the image frame.\n",
    "    # percent: set the banner height as a percentage of the frame height.\n",
    "    banner_height = int(banner_height_percent * frame.shape[0])\n",
    "    cv2.rectangle(frame, (0, 0), (frame.shape[1], banner_height), (0, 0, 0), thickness=-1)\n",
    "\n",
    "    # Draw text on banner.\n",
    "    left_offset = 20\n",
    "    location = (left_offset, int(15 + (banner_height_percent * frame.shape[0]) / 2))\n",
    "    cv2.putText(frame, text, location, cv2.FONT_HERSHEY_SIMPLEX, font_scale, text_color, \n",
    "                font_thickness, cv2.LINE_AA)\n",
    "\n",
    "def drawRectangle(frame, bbox, color=(255,0,0)):\n",
    "    p1 = (int(bbox[0]), int(bbox[1]))\n",
    "    p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "    cv2.rectangle(frame, p1, p2, color, 2, 1)\n",
    "\n",
    "def displayRectangle(frame, bbox, color=(255,0,0)):\n",
    "    plt.figure(figsize=(20,10))\n",
    "    frameCopy = frame.copy()\n",
    "    drawRectangle(frameCopy, bbox, color)\n",
    "    frameCopy = cv2.cvtColor(frameCopy, cv2.COLOR_RGB2BGR)\n",
    "    plt.imshow(frameCopy); plt.axis('off')    \n",
    "     \n",
    "def drawText(frame, text, location=(20,20), font_scale=1, color=(50,170,50), font_thickness=2):\n",
    "    cv2.putText(frame, text, location, cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, \n",
    "                font_thickness, cv2.LINE_AA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 3. Create a Tracker Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up tracker.\n",
    "tracker_types = ['BOOSTING', 'CSRT', 'KCF', 'MEDIANFLOW', 'MIL', 'MOSSE', 'TLD']\n",
    "\n",
    "# Change the index to change the tracker type.\n",
    "tracker_type = tracker_types[0] \n",
    "\n",
    "if tracker_type == 'BOOSTING':\n",
    "    tracker = cv2.legacy.TrackerBoosting_create()\n",
    "elif tracker_type == 'CSRT':\n",
    "    tracker = cv2.legacy.TrackerCSRT_create()\n",
    "elif tracker_type == 'KCF':\n",
    "    tracker = cv2.legacy.TrackerKCF_create()\n",
    "elif tracker_type == 'MEDIANFLOW':\n",
    "    tracker = cv2.legacy.TrackerMedianFlow_create()  \n",
    "elif tracker_type == 'MIL':\n",
    "    tracker = cv2.legacy.TrackerMIL_create()\n",
    "elif tracker_type == 'MOSSE':\n",
    "    tracker = cv2.legacy.TrackerMOSSE_create()\n",
    "elif tracker_type == 'TLD':\n",
    "    tracker = cv2.legacy.TrackerTLD_create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 4.  Create Video Capture and Video Writer Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read video\n",
    "video_input_file_name = \"./race_car.mp4\"\n",
    "\n",
    "# Create output file name for annotated video.\n",
    "video_output_file_name = os.path.splitext(os.path.basename(video_input_file_name))[0]  \\\n",
    "                       + \"_\"  + tracker_type + '.mp4'\n",
    "\n",
    "# Create video capture object.\n",
    "video_cap = cv2.VideoCapture(video_input_file_name)\n",
    "\n",
    "# Read first frame from video.\n",
    "ok, frame = video_cap.read()\n",
    "\n",
    "# Confirm video file can be opened.\n",
    "if video_cap.isOpened():\n",
    "    width  = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps    = int(video_cap.get(cv2.CAP_PROP_FPS))\n",
    "else: \n",
    "    print('Could not open video')\n",
    "    sys.exit()\n",
    "    \n",
    "fps_write = 20    # slow down video for demonstration purposes.\n",
    "\n",
    "# Set up video writer for mp4.\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "# Create video writer object.\n",
    "video_out = cv2.VideoWriter( video_output_file_name, fourcc, fps_write, (width, height) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 5. Define the Initial Bounding Box\n",
    "\n",
    "The initial location of the object will be identified manually in this case. Normally this would be accomplished with an object detection model to identify the object(s) to be tracked. This process is normally referred to as object acquisition or object detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bbox = None\n",
    "# Define a bounding box for the location of the object in the first video frame.\n",
    "bbox = (820, 510, 420, 180) # race car\n",
    "\n",
    "# Check if the a bounding box has been defined. If not, display the initial frame and alow the user to  \n",
    "# manually select the bounding box with the mouse.\n",
    "if bbox == None:\n",
    "    # This will display the first frame of the video. Use the mouse to specify a bounding box\n",
    "    # around the object to track. When done, hit the space bar or Enter key to complete the operation.\n",
    "    bbox = cv2.selectROI(frame, False)  # Note: this may cause python to hang on Mac OS.\n",
    "    print(bbox)\n",
    "    \n",
    "frame_copy = frame.copy() \n",
    "displayRectangle(frame_copy, bbox, color=(0, 255, 255))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <font style=\"color:rgb(50,120,229)\">Tracking API</font>\n",
    "\n",
    "<hr style=\"border:none; height: 4px; background-color:#D3D3D3\" />\n",
    "\n",
    "### <font color=\"green\">OpenCV Documentation</font>\n",
    "\n",
    "[**`Tracker Class`**](https://docs.opencv.org/4.5.2/d0/d0a/classcv_1_1Tracker.html)\n",
    "\n",
    "<hr style=\"border:none; height: 4px; background-color:#D3D3D3\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Intilialize Tracker \n",
    "\n",
    "The tracker object is initialized with a single video frame and a bounding box to identify the initial location of the object. In a more advanced application the object of interest would be detected automatically using an object detection model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the tracker with the first frame and a bounding box to identify the object of interest.\n",
    "tracker.init(frame, bbox);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 7. Processes Video Frames and Track Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ok, frame = video_cap.read()\n",
    "    if not ok:\n",
    "        break \n",
    "    \n",
    "    # Start timer\n",
    "    timer = cv2.getTickCount()\n",
    "\n",
    "    # Update tracker\n",
    "    ok, bbox = tracker.update(frame)\n",
    "\n",
    "    # Calculate Frames per second (FPS)\n",
    "    fps = cv2.getTickFrequency() / (cv2.getTickCount() - timer);\n",
    "\n",
    "    # Draw bounding box\n",
    "    if ok:\n",
    "        drawRectangle(frame, bbox, color=(0, 255, 255))\n",
    "    else:\n",
    "        drawText(frame, 'Tracking failure detected', location=(80,140), color=(0, 0, 255))\n",
    "\n",
    "    # Display Info\n",
    "    drawBannerText(frame, tracker_type + ' Tracker' + ', FPS : ' + str(int(fps)))\n",
    "    \n",
    "    # Write frame to video\n",
    "    video_out.write(frame)\n",
    "    \n",
    "video_cap.release()\n",
    "video_out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = VideoFileClip(video_output_file_name)\n",
    "clip = clip.resize(height=600)\n",
    "clip.ipython_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = VideoFileClip('./race_car_CSRT.mp4')\n",
    "clip = clip.resize(height=600)\n",
    "clip.ipython_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = VideoFileClip('./race_car_KCF.mp4')\n",
    "clip = clip.resize(height=600)\n",
    "clip.ipython_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = VideoFileClip('./race_car_MEDIANFLOW.mp4')\n",
    "clip = clip.resize(height=600)\n",
    "clip.ipython_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = VideoFileClip('./race_car_MIL.mp4')\n",
    "clip = clip.resize(height=600)\n",
    "clip.ipython_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = VideoFileClip('./race_car_MOSSE.mp4')\n",
    "clip = clip.resize(height=600)\n",
    "clip.ipython_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = VideoFileClip('./race_car_TLD.mp4')\n",
    "clip = clip.resize(height=600)\n",
    "clip.ipython_display()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
